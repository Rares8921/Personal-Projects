{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElWNufDzdnRK",
        "outputId": "69616577-699e-4948-9257-8978f4726f6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9884520014169323\n",
            "[False  True  True ... False False  True]\n"
          ]
        }
      ],
      "source": [
        "#The train data is too big to be uploaded on github :/",
        "import numpy as np #\n",
        "import pandas as pd #\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "# Using CountVectorizer, the text is converted into a \"frequency matrix\"\n",
        "# With TfidfTransformer, that matrix is converted into a term frequency-inverse document frequency representation\n",
        "from sklearn.model_selection import train_test_split # To split the training data\n",
        "from sklearn.pipeline import Pipeline # With the pipeline, I basically chain together multiple estimation tools into a single one. It links all the steps to process the data to create the pipeline\n",
        "from sklearn.svm import LinearSVC # LinearSVC - linear support vector machine\n",
        "\n",
        "# Extract the data for training\n",
        "trainCsv = pd.read_csv(\"train.csv\", index_col = \"id\")\n",
        "# Columns containing null/nan values will be filled with empty text\n",
        "trainCsv['title'] = trainCsv['title'].fillna(\"\")\n",
        "trainCsv['content'] = trainCsv['content'].fillna(\"\")\n",
        "# So columns without text will be designated with 0, and 0 means the text is not satire\n",
        "trainCsv['class'] = trainCsv['class'].fillna(0)\n",
        "\n",
        "textTrain, textTest, yTrain, yTest = train_test_split(trainCsv[\"title\"]+trainCsv[\"content\"], trainCsv[\"class\"], test_size = 0.2, random_state = 42)\n",
        "vectors = CountVectorizer(ngram_range=(1, 2), stop_words = None, lowercase = True, max_df = 0.8, min_df = 20)\n",
        "tfidf = TfidfTransformer()\n",
        "# C is a regularization parameter, and regularization is inversely proportional to the parameter C\n",
        "svMachine = LinearSVC(C = 100.0)\n",
        "# The arguments are the 'steps' of data processing and now I merge them into a single entity through which I train\n",
        "trainModel = Pipeline([('vect', vectors), ('tfidf', tfidf), ('svMachine', svMachine)])\n",
        "\n",
        "# Training process\n",
        "trainModel.fit(textTrain, yTrain)\n",
        "#print(trainModel.score(textTest, yTest))\n",
        "#print(trainModel.predict(textTest))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLAf3A6Z_TiS"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFL8n7Myd4cV"
      },
      "outputs": [],
      "source": [
        "# Saving the answer\n",
        "testCsv = pd.read_csv(\"test.csv\", index_col=\"id\")\n",
        "trainCsv['title'] = trainCsv['title'].fillna(\"\")\n",
        "trainCsv['content'] = trainCsv['content'].fillna(\"\")\n",
        "rasp = trainModel.predict(trainCsv['title'] + trainCsv['content'])\n",
        "with open('raspuns.csv','w') as w:\n",
        "  w.write('id,class\\n\\n\\n')\n",
        "  for e,i in enumerate(rasp):\n",
        "    w.write(f'{e}, {int(i)}\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVosTowJm4K3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
